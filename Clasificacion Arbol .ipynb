{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn import tree\n",
      "\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "\n",
      "from utils import open_eros_data\n",
      "from utils import plot_confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clasificacion de datos EROS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = open_eros_data()\n",
      "\n",
      "num_classes = len(y.unique())\n",
      "feature_names = X.columns.tolist()\n",
      "\n",
      "# Guardamos las predicciones y clases reales de todos los fold en una lista\n",
      "y_pred_total = []\n",
      "y_test_total = []\n",
      "\n",
      "k_fold = cross_validation.StratifiedKFold(y, n_folds = 10, indices = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Para cada fold, ajustamos un \u00e1rbol con el 90% de los datos y guardamos sus predicciones sobre el 10% restante\n",
      "for train_indices, test_indices in k_fold:\n",
      "    X_train = X.iloc[train_indices]\n",
      "    y_train = y.iloc[train_indices]\n",
      "\n",
      "    X_test = X.iloc[test_indices]\n",
      "    y_test = y.iloc[test_indices]\n",
      "\n",
      "    clf = tree.DecisionTreeClassifier( criterion = 'entropy')\n",
      "\n",
      "    # Ajusto el modelo y predigo \n",
      "    clf = clf.fit( X_train, y_train )\n",
      "    y_pred = clf.predict( X_test )\n",
      "\n",
      "    y_pred_total += y_pred.tolist()\n",
      "    y_test_total += y_test.tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Metricas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "import pandas as pd\n",
      "\n",
      "# Calculamos las m\u00e9tricas de calidad de la clasificaci\u00f3n\n",
      "precision = precision_score(y_test_total, y_pred_total, average = None)\n",
      "recall = recall_score(y_test_total, y_pred_total, average = None)\n",
      "f_score = f1_score(y_test_total, y_pred_total, average = None)\n",
      "\n",
      "df = pd.DataFrame([precision, recall, f_score], index = ['Precision', 'Recall', 'F-Score'])\n",
      "\n",
      "HTML(df.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Precision</th>\n",
        "      <td> 0.948428</td>\n",
        "      <td> 0.914110</td>\n",
        "      <td> 0.907258</td>\n",
        "      <td> 0.883191</td>\n",
        "      <td> 0.993683</td>\n",
        "      <td> 0.808989</td>\n",
        "      <td> 0.933659</td>\n",
        "      <td> 0.270677</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Recall</th>\n",
        "      <td> 0.947236</td>\n",
        "      <td> 0.914511</td>\n",
        "      <td> 0.880626</td>\n",
        "      <td> 0.876201</td>\n",
        "      <td> 0.993434</td>\n",
        "      <td> 0.800000</td>\n",
        "      <td> 0.941387</td>\n",
        "      <td> 0.297521</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>F-Score</th>\n",
        "      <td> 0.947832</td>\n",
        "      <td> 0.914311</td>\n",
        "      <td> 0.893744</td>\n",
        "      <td> 0.879682</td>\n",
        "      <td> 0.993558</td>\n",
        "      <td> 0.804469</td>\n",
        "      <td> 0.937507</td>\n",
        "      <td> 0.283465</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<IPython.core.display.HTML at 0x108b2b490>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Matriz de Confusi\u00f3n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ploteamos matriz de confusi\u00f3n como Heatmap\n",
      "plot_confusion_matrix(y_test_total, y_pred_total, 'Decision Tree Classifier', normed=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Visualizaci\u00f3n del Arbol"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals.six import StringIO  \n",
      "from sklearn import tree\n",
      "import pydot \n",
      "\n",
      "# Volvemos a entrenar un \u00e1rbol pero con todos los datos\n",
      "clf = clf.fit(X,y)\n",
      "\n",
      "dot_data = StringIO() \n",
      "tree.export_graphviz(clf, out_file=dot_data, feature_names=feature_names) \n",
      "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
      "graph.write_pdf(\"Eros_Tree.pdf\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}